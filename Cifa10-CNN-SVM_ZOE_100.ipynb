{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RgCmaNtELWcf"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.datasets import cifar10\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oS3YtyW6LylX"
   },
   "outputs": [],
   "source": [
    "\n",
    "def lr_schedule(epoch):\n",
    "    lrate = 0.001\n",
    "    if epoch > 75:\n",
    "        lrate = 0.0005\n",
    "    elif epoch > 100:\n",
    "        lrate = 0.0003        \n",
    "    return lrate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0YR14RboL092"
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "owhH_qeQL2iK"
   },
   "outputs": [],
   "source": [
    "#z-score\n",
    "mean = np.mean(x_train,axis=(0,1,2,3))\n",
    "std = np.std(x_train,axis=(0,1,2,3))\n",
    "x_train = (x_train-mean)/(std+1e-7)\n",
    "x_test = (x_test-mean)/(std+1e-7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_bcoHpJHL4O-"
   },
   "outputs": [],
   "source": [
    "\n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train,num_classes)\n",
    "y_test = np_utils.to_categorical(y_test,num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5trHgDGhL7Hc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 309,290\n",
      "Trainable params: 308,394\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "weight_decay = 1e-4\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay), input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(32, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(64, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(128, (3,3), padding='same', kernel_regularizer=regularizers.l2(weight_decay)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yRtQFAI4L9j7"
   },
   "outputs": [],
   "source": [
    "#data augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    )\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "criRkp0fMOmO",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 1.8777 - acc: 0.4307 - val_loss: 1.3583 - val_acc: 0.5956\n",
      "Epoch 2/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 1.2482 - acc: 0.5986 - val_loss: 1.3860 - val_acc: 0.6168\n",
      "Epoch 3/100\n",
      "781/781 [==============================] - 178s 227ms/step - loss: 1.0716 - acc: 0.6558 - val_loss: 1.0290 - val_acc: 0.6917\n",
      "Epoch 4/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.9684 - acc: 0.6935 - val_loss: 0.8218 - val_acc: 0.7541\n",
      "Epoch 5/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.9023 - acc: 0.7185 - val_loss: 0.8201 - val_acc: 0.7621\n",
      "Epoch 6/100\n",
      "781/781 [==============================] - 178s 227ms/step - loss: 0.8568 - acc: 0.7384 - val_loss: 0.7786 - val_acc: 0.7725\n",
      "Epoch 7/100\n",
      "781/781 [==============================] - 177s 227ms/step - loss: 0.8242 - acc: 0.7516 - val_loss: 0.7711 - val_acc: 0.7741\n",
      "Epoch 8/100\n",
      "781/781 [==============================] - 177s 227ms/step - loss: 0.7926 - acc: 0.7616 - val_loss: 0.8039 - val_acc: 0.7704\n",
      "Epoch 9/100\n",
      "781/781 [==============================] - 177s 227ms/step - loss: 0.7750 - acc: 0.7704 - val_loss: 0.7532 - val_acc: 0.7851\n",
      "Epoch 10/100\n",
      "781/781 [==============================] - 177s 227ms/step - loss: 0.7569 - acc: 0.7781 - val_loss: 0.7409 - val_acc: 0.7926\n",
      "Epoch 11/100\n",
      "781/781 [==============================] - 177s 227ms/step - loss: 0.7385 - acc: 0.7855 - val_loss: 0.7014 - val_acc: 0.8085\n",
      "Epoch 12/100\n",
      "781/781 [==============================] - 177s 227ms/step - loss: 0.7252 - acc: 0.7904 - val_loss: 0.7576 - val_acc: 0.7931\n",
      "Epoch 13/100\n",
      "781/781 [==============================] - 177s 227ms/step - loss: 0.7214 - acc: 0.7941 - val_loss: 0.7032 - val_acc: 0.8079\n",
      "Epoch 14/100\n",
      "781/781 [==============================] - 178s 227ms/step - loss: 0.7095 - acc: 0.8009 - val_loss: 0.6914 - val_acc: 0.8088\n",
      "Epoch 15/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.6946 - acc: 0.8053 - val_loss: 0.7085 - val_acc: 0.8112\n",
      "Epoch 16/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.6898 - acc: 0.8068 - val_loss: 0.6308 - val_acc: 0.8363\n",
      "Epoch 17/100\n",
      "781/781 [==============================] - 179s 230ms/step - loss: 0.6802 - acc: 0.8114 - val_loss: 0.8018 - val_acc: 0.7905\n",
      "Epoch 18/100\n",
      "781/781 [==============================] - 179s 230ms/step - loss: 0.6710 - acc: 0.8149 - val_loss: 0.7004 - val_acc: 0.8116\n",
      "Epoch 19/100\n",
      "781/781 [==============================] - 180s 230ms/step - loss: 0.6723 - acc: 0.8160 - val_loss: 0.6686 - val_acc: 0.8194\n",
      "Epoch 20/100\n",
      "781/781 [==============================] - 180s 231ms/step - loss: 0.6662 - acc: 0.8179 - val_loss: 0.5964 - val_acc: 0.8447\n",
      "Epoch 21/100\n",
      "781/781 [==============================] - 180s 230ms/step - loss: 0.6645 - acc: 0.8169 - val_loss: 0.6173 - val_acc: 0.8366\n",
      "Epoch 22/100\n",
      "781/781 [==============================] - 179s 229ms/step - loss: 0.6542 - acc: 0.8232 - val_loss: 0.6676 - val_acc: 0.8199\n",
      "Epoch 23/100\n",
      "781/781 [==============================] - 179s 229ms/step - loss: 0.6487 - acc: 0.8242 - val_loss: 0.5953 - val_acc: 0.8441\n",
      "Epoch 24/100\n",
      "781/781 [==============================] - 179s 229ms/step - loss: 0.6485 - acc: 0.8253 - val_loss: 0.6572 - val_acc: 0.8241\n",
      "Epoch 25/100\n",
      "781/781 [==============================] - 179s 229ms/step - loss: 0.6463 - acc: 0.8254 - val_loss: 0.6254 - val_acc: 0.8417\n",
      "Epoch 26/100\n",
      "781/781 [==============================] - 180s 230ms/step - loss: 0.6389 - acc: 0.8277 - val_loss: 0.6330 - val_acc: 0.8367\n",
      "Epoch 27/100\n",
      "781/781 [==============================] - 179s 230ms/step - loss: 0.6428 - acc: 0.8280 - val_loss: 0.7355 - val_acc: 0.8113\n",
      "Epoch 28/100\n",
      "781/781 [==============================] - 179s 229ms/step - loss: 0.6358 - acc: 0.8286 - val_loss: 0.6515 - val_acc: 0.8344\n",
      "Epoch 29/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.6319 - acc: 0.8310 - val_loss: 0.5899 - val_acc: 0.8509\n",
      "Epoch 30/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.6293 - acc: 0.8332 - val_loss: 0.6047 - val_acc: 0.8422\n",
      "Epoch 31/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.6269 - acc: 0.8335 - val_loss: 0.6378 - val_acc: 0.8404\n",
      "Epoch 32/100\n",
      "781/781 [==============================] - 180s 230ms/step - loss: 0.6303 - acc: 0.8327 - val_loss: 0.6100 - val_acc: 0.8439\n",
      "Epoch 33/100\n",
      "781/781 [==============================] - 179s 229ms/step - loss: 0.6211 - acc: 0.8374 - val_loss: 0.5767 - val_acc: 0.8579\n",
      "Epoch 34/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.6181 - acc: 0.8364 - val_loss: 0.5694 - val_acc: 0.8581\n",
      "Epoch 35/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.6210 - acc: 0.8370 - val_loss: 0.5665 - val_acc: 0.8575\n",
      "Epoch 36/100\n",
      "781/781 [==============================] - 177s 227ms/step - loss: 0.6120 - acc: 0.8398 - val_loss: 0.5933 - val_acc: 0.8519\n",
      "Epoch 37/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.6134 - acc: 0.8399 - val_loss: 0.6209 - val_acc: 0.8408\n",
      "Epoch 38/100\n",
      "781/781 [==============================] - 180s 230ms/step - loss: 0.6123 - acc: 0.8397 - val_loss: 0.5556 - val_acc: 0.8644\n",
      "Epoch 39/100\n",
      "781/781 [==============================] - 178s 229ms/step - loss: 0.6091 - acc: 0.8431 - val_loss: 0.6146 - val_acc: 0.8493\n",
      "Epoch 40/100\n",
      "781/781 [==============================] - 178s 227ms/step - loss: 0.6150 - acc: 0.8399 - val_loss: 0.6938 - val_acc: 0.8270\n",
      "Epoch 41/100\n",
      "781/781 [==============================] - 178s 227ms/step - loss: 0.6079 - acc: 0.8405 - val_loss: 0.5576 - val_acc: 0.8647\n",
      "Epoch 42/100\n",
      "781/781 [==============================] - 177s 227ms/step - loss: 0.6072 - acc: 0.8431 - val_loss: 0.6306 - val_acc: 0.8413\n",
      "Epoch 43/100\n",
      "781/781 [==============================] - 177s 227ms/step - loss: 0.6069 - acc: 0.8427 - val_loss: 0.7056 - val_acc: 0.8282\n",
      "Epoch 44/100\n",
      "781/781 [==============================] - 177s 227ms/step - loss: 0.6046 - acc: 0.8443 - val_loss: 0.6059 - val_acc: 0.8437\n",
      "Epoch 45/100\n",
      "781/781 [==============================] - 179s 229ms/step - loss: 0.6010 - acc: 0.8442 - val_loss: 0.6204 - val_acc: 0.8449\n",
      "Epoch 46/100\n",
      "781/781 [==============================] - 180s 230ms/step - loss: 0.6021 - acc: 0.8450 - val_loss: 0.6398 - val_acc: 0.8419\n",
      "Epoch 47/100\n",
      "781/781 [==============================] - 179s 229ms/step - loss: 0.5972 - acc: 0.8459 - val_loss: 0.6328 - val_acc: 0.8434\n",
      "Epoch 48/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.6002 - acc: 0.8451 - val_loss: 0.5849 - val_acc: 0.8568\n",
      "Epoch 49/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.6005 - acc: 0.8451 - val_loss: 0.5855 - val_acc: 0.8549\n",
      "Epoch 50/100\n",
      "781/781 [==============================] - 178s 227ms/step - loss: 0.5915 - acc: 0.8491 - val_loss: 0.5762 - val_acc: 0.8612\n",
      "Epoch 51/100\n",
      "781/781 [==============================] - 177s 227ms/step - loss: 0.5966 - acc: 0.8450 - val_loss: 0.6524 - val_acc: 0.8377\n",
      "Epoch 52/100\n",
      "781/781 [==============================] - 177s 227ms/step - loss: 0.5968 - acc: 0.8463 - val_loss: 0.6284 - val_acc: 0.8424\n",
      "Epoch 53/100\n",
      "781/781 [==============================] - 177s 227ms/step - loss: 0.5872 - acc: 0.8492 - val_loss: 0.6362 - val_acc: 0.8461\n",
      "Epoch 54/100\n",
      "781/781 [==============================] - 177s 226ms/step - loss: 0.5957 - acc: 0.8455 - val_loss: 0.6053 - val_acc: 0.8538\n",
      "Epoch 55/100\n",
      "781/781 [==============================] - 177s 227ms/step - loss: 0.5934 - acc: 0.8475 - val_loss: 0.5609 - val_acc: 0.8599\n",
      "Epoch 56/100\n",
      "781/781 [==============================] - 180s 230ms/step - loss: 0.5866 - acc: 0.8510 - val_loss: 0.5718 - val_acc: 0.8592\n",
      "Epoch 57/100\n",
      "781/781 [==============================] - 179s 229ms/step - loss: 0.5894 - acc: 0.8491 - val_loss: 0.6224 - val_acc: 0.8455\n",
      "Epoch 58/100\n",
      "781/781 [==============================] - 179s 229ms/step - loss: 0.5902 - acc: 0.8498 - val_loss: 0.6002 - val_acc: 0.8551\n",
      "Epoch 59/100\n",
      "781/781 [==============================] - 179s 229ms/step - loss: 0.5873 - acc: 0.8508 - val_loss: 0.5963 - val_acc: 0.8513\n",
      "Epoch 60/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.5852 - acc: 0.8506 - val_loss: 0.6208 - val_acc: 0.8491\n",
      "Epoch 61/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.5847 - acc: 0.8501 - val_loss: 0.5520 - val_acc: 0.8659\n",
      "Epoch 62/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.5855 - acc: 0.8510 - val_loss: 0.6419 - val_acc: 0.8409\n",
      "Epoch 63/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.5819 - acc: 0.8500 - val_loss: 0.6331 - val_acc: 0.8426\n",
      "Epoch 64/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.5806 - acc: 0.8528 - val_loss: 0.6472 - val_acc: 0.8356\n",
      "Epoch 65/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.5802 - acc: 0.8532 - val_loss: 0.6238 - val_acc: 0.8467\n",
      "Epoch 66/100\n",
      "781/781 [==============================] - 178s 227ms/step - loss: 0.5842 - acc: 0.8515 - val_loss: 0.6099 - val_acc: 0.8491\n",
      "Epoch 67/100\n",
      "781/781 [==============================] - 177s 227ms/step - loss: 0.5756 - acc: 0.8539 - val_loss: 0.5922 - val_acc: 0.8605\n",
      "Epoch 68/100\n",
      "781/781 [==============================] - 177s 227ms/step - loss: 0.5837 - acc: 0.8517 - val_loss: 0.5572 - val_acc: 0.8628\n",
      "Epoch 69/100\n",
      "781/781 [==============================] - 177s 227ms/step - loss: 0.5801 - acc: 0.8525 - val_loss: 0.5436 - val_acc: 0.8682\n",
      "Epoch 70/100\n",
      "781/781 [==============================] - 177s 226ms/step - loss: 0.5754 - acc: 0.8552 - val_loss: 0.7004 - val_acc: 0.8258\n",
      "Epoch 71/100\n",
      "781/781 [==============================] - 177s 227ms/step - loss: 0.5743 - acc: 0.8552 - val_loss: 0.6125 - val_acc: 0.8548\n",
      "Epoch 72/100\n",
      "781/781 [==============================] - 180s 230ms/step - loss: 0.5803 - acc: 0.8534 - val_loss: 0.5889 - val_acc: 0.8555\n",
      "Epoch 73/100\n",
      "781/781 [==============================] - 179s 230ms/step - loss: 0.5745 - acc: 0.8541 - val_loss: 0.6084 - val_acc: 0.8550\n",
      "Epoch 74/100\n",
      "781/781 [==============================] - 179s 230ms/step - loss: 0.5795 - acc: 0.8522 - val_loss: 0.6295 - val_acc: 0.8453\n",
      "Epoch 75/100\n",
      "781/781 [==============================] - 179s 229ms/step - loss: 0.5732 - acc: 0.8556 - val_loss: 0.6057 - val_acc: 0.8518\n",
      "Epoch 76/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.5793 - acc: 0.8551 - val_loss: 0.5903 - val_acc: 0.8572\n",
      "Epoch 77/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.5286 - acc: 0.8712 - val_loss: 0.5361 - val_acc: 0.8750\n",
      "Epoch 78/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.5133 - acc: 0.8738 - val_loss: 0.5411 - val_acc: 0.8703\n",
      "Epoch 79/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.5098 - acc: 0.8732 - val_loss: 0.5119 - val_acc: 0.8796\n",
      "Epoch 80/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.5007 - acc: 0.8765 - val_loss: 0.5268 - val_acc: 0.8741\n",
      "Epoch 81/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.4924 - acc: 0.8768 - val_loss: 0.5268 - val_acc: 0.8712\n",
      "Epoch 82/100\n",
      "781/781 [==============================] - 177s 227ms/step - loss: 0.4886 - acc: 0.8791 - val_loss: 0.5230 - val_acc: 0.8758\n",
      "Epoch 83/100\n",
      "781/781 [==============================] - 177s 227ms/step - loss: 0.4858 - acc: 0.8798 - val_loss: 0.5449 - val_acc: 0.8645\n",
      "Epoch 84/100\n",
      "781/781 [==============================] - 178s 227ms/step - loss: 0.4820 - acc: 0.8790 - val_loss: 0.5376 - val_acc: 0.8706\n",
      "Epoch 85/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.4832 - acc: 0.8784 - val_loss: 0.4904 - val_acc: 0.8808\n",
      "Epoch 86/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.4804 - acc: 0.8770 - val_loss: 0.4913 - val_acc: 0.8807\n",
      "Epoch 87/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.4738 - acc: 0.8798 - val_loss: 0.5165 - val_acc: 0.8785\n",
      "Epoch 88/100\n",
      "781/781 [==============================] - 181s 231ms/step - loss: 0.4679 - acc: 0.8821 - val_loss: 0.5076 - val_acc: 0.8762\n",
      "Epoch 89/100\n",
      "781/781 [==============================] - 180s 231ms/step - loss: 0.4671 - acc: 0.8812 - val_loss: 0.5312 - val_acc: 0.8687\n",
      "Epoch 90/100\n",
      "781/781 [==============================] - 180s 230ms/step - loss: 0.4700 - acc: 0.8808 - val_loss: 0.5403 - val_acc: 0.8617\n",
      "Epoch 91/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.4650 - acc: 0.8827 - val_loss: 0.5135 - val_acc: 0.8781\n",
      "Epoch 92/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.4637 - acc: 0.8819 - val_loss: 0.4576 - val_acc: 0.8881\n",
      "Epoch 93/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.4689 - acc: 0.8788 - val_loss: 0.4976 - val_acc: 0.8780\n",
      "Epoch 94/100\n",
      "781/781 [==============================] - 178s 228ms/step - loss: 0.4634 - acc: 0.8815 - val_loss: 0.5104 - val_acc: 0.8733\n",
      "Epoch 95/100\n",
      "781/781 [==============================] - 177s 227ms/step - loss: 0.4618 - acc: 0.8811 - val_loss: 0.4966 - val_acc: 0.8803\n",
      "Epoch 96/100\n",
      "781/781 [==============================] - 177s 227ms/step - loss: 0.4635 - acc: 0.8805 - val_loss: 0.5010 - val_acc: 0.8782\n",
      "Epoch 97/100\n",
      "781/781 [==============================] - 179s 229ms/step - loss: 0.4619 - acc: 0.8810 - val_loss: 0.4932 - val_acc: 0.8752\n",
      "Epoch 98/100\n",
      "781/781 [==============================] - 180s 230ms/step - loss: 0.4528 - acc: 0.8845 - val_loss: 0.4734 - val_acc: 0.8822\n",
      "Epoch 99/100\n",
      "781/781 [==============================] - 179s 229ms/step - loss: 0.4625 - acc: 0.8814 - val_loss: 0.4849 - val_acc: 0.8780\n",
      "Epoch 100/100\n",
      "781/781 [==============================] - 179s 229ms/step - loss: 0.4571 - acc: 0.8827 - val_loss: 0.5473 - val_acc: 0.8603\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7bad662400>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training\n",
    "batch_size = 64\n",
    "\n",
    "opt_rms = keras.optimizers.rmsprop(lr=0.001,decay=1e-6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt_rms, metrics=['accuracy'])\n",
    "model.fit_generator(datagen.flow(x_train, y_train, batch_size=batch_size),\\\n",
    "                    steps_per_epoch=x_train.shape[0] // batch_size,epochs=100,\\\n",
    "                    verbose=1,validation_data=(x_test,y_test),callbacks=[LearningRateScheduler(lr_schedule)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bol61qMdMQ1G"
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "You must compile a model before training/testing. Use `model.compile(optimizer, loss)`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-42fa6eaa9b75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#testing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\nTest result: %.3f loss: %.3f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps)\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Prepare inputs, delegate logic to `test_loop`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    679\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 681\u001b[0;31m                 raise RuntimeError('You must compile a model before '\n\u001b[0m\u001b[1;32m    682\u001b[0m                                    \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m                                    'Use `model.compile(optimizer, loss)`.')\n",
      "\u001b[0;31mRuntimeError\u001b[0m: You must compile a model before training/testing. Use `model.compile(optimizer, loss)`."
     ]
    }
   ],
   "source": [
    "#save to disk\n",
    "model_json = model.to_json()\n",
    "with open('model.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "model.save_weights('model.h5')    \n",
    "\n",
    "#testing\n",
    "scores = model.evaluate(x_test, y_test, batch_size=128, verbose=1)\n",
    "print('\\nTest result: %.3f loss: %.3f' % (scores[1]*100,scores[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.layers.convolutional.Conv2D at 0x7f7bad673978>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_layer = model.layers[0]\n",
    "top_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f7b27e6b8d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(top_layer.get_weights()[0][2:, :, :, 30].squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-27-18ae24210207>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-27-18ae24210207>\"\u001b[0;36m, line \u001b[0;32m5\u001b[0m\n\u001b[0;31m    json.dump(history_dict, open('home/dp1@it079824/Document/zoeML/Assginment2/model', 'w'))\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Get the dictionary containing each metric and the loss for each epoch\n",
    "history_dict = json.load(open('home/dp1@it079824/Document/zoeML/Assginment2/model', 'r')\n",
    "# Save it under the form of a json file\n",
    "json.dump(history_dict, open('home/dp1@it079824/Document/zoeML/Assginment2/model', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Sequential' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-cbd185d71921>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "history = model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Callback' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-b65c29871770>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 绘制训练 & 验证的准确率值\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Callback' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "# 绘制训练 & 验证的准确率值\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# 绘制训练 & 验证的损失值\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-a70009143d02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'model.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2cabf02ce23a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mSVG\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dot'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'svg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils \\\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
